[2024-07-25T17:57:59.902+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-25T17:57:59.913+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: list_db_tables.log_table_names manual__2024-07-25T17:57:57.843104+00:00 [queued]>
[2024-07-25T17:57:59.916+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: list_db_tables.log_table_names manual__2024-07-25T17:57:57.843104+00:00 [queued]>
[2024-07-25T17:57:59.916+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-07-25T17:57:59.921+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): log_table_names> on 2024-07-25 17:57:57.843104+00:00
[2024-07-25T17:57:59.925+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:62: DeprecationWarning: This process (pid=110) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-25T17:57:59.926+0000] {standard_task_runner.py:64} INFO - Started process 112 to run task
[2024-07-25T17:57:59.926+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'list_db_tables', 'log_table_names', 'manual__2024-07-25T17:57:57.843104+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/print_sql_request_dag.py', '--cfg-path', '/tmp/tmpfppdvifa']
[2024-07-25T17:57:59.928+0000] {standard_task_runner.py:91} INFO - Job 15: Subtask log_table_names
[2024-07-25T17:57:59.948+0000] {task_command.py:426} INFO - Running <TaskInstance: list_db_tables.log_table_names manual__2024-07-25T17:57:57.843104+00:00 [running]> on host 9cfb47510abc
[2024-07-25T17:57:59.982+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='list_db_tables' AIRFLOW_CTX_TASK_ID='log_table_names' AIRFLOW_CTX_EXECUTION_DATE='2024-07-25T17:57:57.843104+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-25T17:57:57.843104+00:00'
[2024-07-25T17:57:59.984+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-25T17:57:59.990+0000] {print_sql_request_dag.py:18} INFO - Tables in the database: [['job'], ['slot_pool'], ['log'], ['dag_code'], ['dag_pickle'], ['ab_user'], ['ab_register_user'], ['connection'], ['callback_request'], ['import_error'], ['sla_miss'], ['variable'], ['serialized_dag'], ['dataset'], ['dag_schedule_dataset_reference'], ['dag'], ['task_outlet_dataset_reference'], ['dataset_dag_run_queue'], ['log_template'], ['dag_run'], ['dag_tag'], ['dag_owner_attributes'], ['ab_permission'], ['ab_permission_view'], ['ab_view_menu'], ['ab_user_role'], ['ab_role'], ['dag_warning'], ['dagrun_dataset_event'], ['dataset_event'], ['trigger'], ['task_instance'], ['dag_run_note'], ['ab_permission_view_role'], ['task_fail'], ['task_map'], ['task_reschedule'], ['xcom'], ['task_instance_note'], ['rendered_task_instance_fields'], ['session'], ['alembic_version'], ['celery_taskmeta'], ['celery_tasksetmeta']]
[2024-07-25T17:57:59.991+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-07-25T17:57:59.991+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-25T17:57:59.995+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=list_db_tables, task_id=log_table_names, run_id=manual__2024-07-25T17:57:57.843104+00:00, execution_date=20240725T175757, start_date=20240725T175759, end_date=20240725T175759
[2024-07-25T17:58:00.027+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2024-07-25T17:58:00.036+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-25T17:58:00.037+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
